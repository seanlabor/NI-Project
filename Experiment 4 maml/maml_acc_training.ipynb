{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "945d7648-148d-4fbd-ae17-10e93bd68526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 15:17:59.137296: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf # use the tf2.4\n",
    "import tensorflow_datasets as tfds \n",
    "import tensorflow_addons as tfa\n",
    "from adabelief_tf import AdaBeliefOptimizer\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score\n",
    "from random import shuffle\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098eb815-3e79-4fd7-b122-126aa1597e34",
   "metadata": {},
   "source": [
    "Hier werden wir das Maml — Modell so trainieren, dass wir eine Multiclass — Accuracy bekommen. Dazu verwenden wir One vs Rest und One vs One Methoden wie in https://scikit-learn.org/stable/modules/multiclass.html dokumentiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abaf323-4e15-47b9-9e42-793a5241c497",
   "metadata": {},
   "source": [
    "### Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16561375-b329-4849-9a4e-64910b7f1b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 28 15:18:22 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   30C    P8    14W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   36C    P8    14W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla T4            Off  | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   34C    P8    14W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a687c62-e9ae-4e1e-8e3a-431b53fa8100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9d052b-c940-4fe0-a87d-bf648f230ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 15:18:23.988289: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-28 15:18:31.076384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12848 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5\n",
      "2022-07-28 15:18:31.078650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 12848 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:af:00.0, compute capability: 7.5\n",
      "2022-07-28 15:18:31.080692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 12848 MB memory:  -> device: 2, name: Tesla T4, pci bus id: 0000:d8:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "(kmnist_tr, kmnist_ts) = tfds.load('kmnist', \n",
    "                                   split=['train','test'],\n",
    "                                   shuffle_files=True,\n",
    "                                   as_supervised=True,\n",
    "                                   with_info=False,)\n",
    "\n",
    "kmnist_tr = kmnist_tr.apply(lambda ds: ds.map(lambda x, y: (x, y + 60)))\n",
    "kmnist_ts = kmnist_ts.apply(lambda ds: ds.map(lambda x, y: (x, y + 60)))\n",
    "\n",
    "\n",
    "\n",
    "(emnist_tr, emnist_ts) = tfds.load('emnist', \n",
    "                                   split=['train','test'],\n",
    "                                   shuffle_files=True,\n",
    "                                   as_supervised=True,\n",
    "                                   with_info=False,)\n",
    "\n",
    "kmnist_tr = kmnist_tr.concatenate(emnist_tr).shuffle(100000)\n",
    "kmnist_ts = kmnist_ts.concatenate(emnist_ts).shuffle(100000)\n",
    "\n",
    "\n",
    "kmnist_tr = kmnist_tr.apply(lambda ds: ds.map(\n",
    "        lambda x, y: \n",
    "            (tf.reshape(x, [1, 28, 28, 1]), y)\n",
    "        ))\n",
    "kmnist_ts = kmnist_ts.apply(lambda ds: ds.map(\n",
    "        lambda x, y: \n",
    "            (tf.reshape(x, [1, 28, 28, 1]), y)\n",
    "        ))\n",
    "\n",
    "out_of_distro_classes_list = [60, 61, 5, 14, 17]\n",
    "out_of_distro_tr = dict()\n",
    "in_of_distro_tr = dict()\n",
    "\n",
    "#collects all classes for out_of_distro_tr\n",
    "# Todo: (5, 14, 17 funktioniert nicht)\n",
    "for ofd in out_of_distro_classes_list:\n",
    "    out_of_distro_tr[ofd] = kmnist_tr.filter(lambda x, y: int(y) == ofd)\n",
    "    out_of_distro_tr[ofd] = out_of_distro_tr[ofd].shuffle(1000)\n",
    "\n",
    "    \n",
    "# collects all opposite classes for in_of_distro_tr\n",
    "for ofd in out_of_distro_classes_list:\n",
    "    is_first_time = True\n",
    "    for ofd_inner in out_of_distro_classes_list:\n",
    "        if ofd_inner == ofd:\n",
    "            continue\n",
    "        if is_first_time:\n",
    "            in_of_distro_tr[ofd] = out_of_distro_tr[ofd_inner]\n",
    "            is_first_time = False\n",
    "        else:\n",
    "            in_of_distro_tr[ofd] = in_of_distro_tr[ofd].concatenate(out_of_distro_tr[ofd_inner])\n",
    "    in_of_distro_tr[ofd] = in_of_distro_tr[ofd].shuffle(1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126e8ac5-a563-436c-b9a4-06a0ad62bf7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Äußeres Modell trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a6ca0c7-9918-4bf0-82c8-3302d52e7a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 14:38:38.846207: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inner_lr = 1E-5\n",
    "outter_lr = 1E-5\n",
    "inner_task_loop_no = 64 # give 32 tasks of 2ways-1shot\n",
    "# opt_inner = tf.keras.optimizers.Adagrad(inner_lr)\n",
    "# opt_outter = tf.keras.optimizers.Adagrad(outter_lr, clipnorm=1.)\n",
    "opt_inner = tfa.optimizers.NovoGrad(inner_lr)\n",
    "opt_outter = tfa.optimizers.NovoGrad(outter_lr, clipnorm=1.)\n",
    "# opt_inner = tfa.optimizers.RectifiedAdam(inner_lr)\n",
    "# opt_outter = tfa.optimizers.RectifiedAdam(outter_lr, clipnorm=1.)\n",
    "# opt_inner = AdaBeliefOptimizer(inner_lr)\n",
    "# opt_outter = AdaBeliefOptimizer(outter_lr)\n",
    "# opt_inner = tf.keras.optimizers.SGD(inner_lr, momentum=.0)\n",
    "# opt_outter = tf.keras.optimizers.SGD(outter_lr, momentum=.9, clipnorm=1.)\n",
    "\n",
    "#opt_outter = tfa.optimizers.MovingAverage(opt_outter) # using average strategy in tfa\n",
    "\n",
    "\n",
    "def cnn():\n",
    "    Input = tf.keras.Input([28, 28, 1])\n",
    "    Input_n = Input/128.0 - 1\n",
    "    conv1 = tf.keras.layers.Conv2D(32, [3, 3], strides=(2, 2), padding=\"SAME\", kernel_initializer=\"he_uniform\", activation=tf.nn.relu)(Input_n) #[14,14]\n",
    "    conv2 = tf.keras.layers.Conv2D(64, [3, 3], strides=(2, 2), padding=\"SAME\", kernel_initializer=\"he_uniform\", activation=tf.nn.relu)(conv1) #[7,7]\n",
    "    conv3 = tf.keras.layers.Conv2D(128, [3, 3], strides=(2, 2), padding=\"SAME\", kernel_initializer=\"he_uniform\", activation=tf.nn.relu)(conv2) #[4,4]\n",
    "    fc = tf.keras.layers.Flatten()(conv3)\n",
    "    fc1 = tf.keras.layers.Dense(128, kernel_initializer=\"he_uniform\", activation=tf.nn.relu)(fc)\n",
    "    fc2 = tf.keras.layers.Dense(256, kernel_initializer=\"he_uniform\", activation=tf.nn.relu)(fc1)\n",
    "    fc3 = tf.keras.layers.Dense(512, kernel_initializer=\"he_uniform\", activation=tf.nn.relu)(fc2)\n",
    "    out = tf.keras.layers.Dense(1, kernel_initializer=\"he_uniform\", activation=None)(fc3)\n",
    "    return tf.keras.Model(inputs=Input, outputs=out)\n",
    " \n",
    "def select_support_query_set(dataset_iter):\n",
    "    flag_1 = flag_0 = True\n",
    "    imgs_1_support, labs_1_support = next(dataset_iter)\n",
    "    imgs_0_support, labs_0_support = next(dataset_iter)\n",
    "    support_set = tf.concat([imgs_1_support, imgs_0_support], axis=0)\n",
    "    while(flag_1 or flag_0):\n",
    "        imgs_query, labs_query = next(dataset_iter)\n",
    "        if ((labs_query.numpy() == labs_1_support.numpy()) and flag_1) :\n",
    "            imgs_1_query = tf.Variable(imgs_query)\n",
    "            flag_1 = False\n",
    "        elif ((labs_query.numpy() == labs_0_support.numpy()) and flag_0) :\n",
    "            imgs_0_query = tf.Variable(imgs_query)\n",
    "            flag_0 = False\n",
    "        pass \n",
    "    pass \n",
    "    query_set = tf.concat([imgs_1_query, imgs_0_query], axis=0)\n",
    "    return [support_set, query_set]\n",
    " \n",
    "# Task hint:\n",
    "# this example will use 2ways-1shot for training the MAML.\n",
    "# the inner task loop will set as 30. \n",
    "kmnist_tr = kmnist_tr.batch(1).repeat()\n",
    "kmnist_tr_iter = iter(kmnist_tr)\n",
    "meta_labs = tf.Variable([[1], [0]], dtype=tf.float32)\n",
    "\n",
    "cnn_model = cnn()\n",
    "\n",
    "# according to the TF2 manual, the variable of the model would need to be\n",
    "# initialized, and use it to inferece something is a way to initialize \n",
    "# the varialbe.\n",
    "support_set, query_set = select_support_query_set(kmnist_tr_iter)\n",
    "_ = cnn_model(support_set) # 1)for initializing the model. 2)for define the loss function out-of the loop \n",
    "loss_inner_meta = lambda: tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=meta_labs, logits=cnn_model(support_set)))\n",
    "loss_inner_task = lambda: tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=meta_labs, logits=cnn_model(query_set)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d8e887-f64b-4c52-8560-edb4be929911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  outter_loss: 0.661101222038269\n",
      "step: 1  outter_loss: 0.6601587533950806\n",
      "step: 2  outter_loss: 0.6592254638671875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for step in range(50000):\n",
    "    # keep the original weights for meta-training\n",
    "    meta_weights = [tf.Variable(target_weights) for target_weights in cnn_model.trainable_weights]\n",
    "    \n",
    "    def meta_loss():\n",
    "        loss_outter = 0\n",
    "        for task_count in range(inner_task_loop_no):\n",
    "            # fetch the dataset. The first dataset is always be 1. \n",
    "            # So, the labels will be defined as the meta-labels insteadly. \n",
    "            support_set, query_set = select_support_query_set(kmnist_tr_iter)\n",
    "            \n",
    "            # put the meta-weights into the model\n",
    "            for model_weight_index in range(len(cnn_model.trainable_weights)):\n",
    "                cnn_model.trainable_weights[model_weight_index].assign(meta_weights[model_weight_index])\n",
    "            pass\n",
    "\n",
    "            # updateing the weights from meta-weights\n",
    "            opt_inner.minimize(loss=loss_inner_meta, var_list=cnn_model.trainable_weights) \n",
    "            \n",
    "            # calculating the task loss (after the meta-weights updating)\n",
    "            # here, the same support set and query set are used. you can \n",
    "            # also creat a different query set for meta-weight training.\n",
    "            loss_outter += loss_inner_task()\n",
    "        pass \n",
    "        return loss_outter/inner_task_loop_no\n",
    "    pass \n",
    "\n",
    "    # put the meta-weights into the model\n",
    "    for model_weight_index in range(len(cnn_model.trainable_weights)):\n",
    "        cnn_model.trainable_weights[model_weight_index].assign(meta_weights[model_weight_index])\n",
    "    pass\n",
    "\n",
    "    # update the meta-weights\n",
    "    opt_outter.minimize(loss=meta_loss, var_list=cnn_model.trainable_weights) \n",
    "    \n",
    "    if step > 2:\n",
    "        break\n",
    "\n",
    "    print(\"step: {}  outter_loss: {}\".format(step, meta_loss()))\n",
    "   #summary_writer.add_scalar(\"t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21990f1f-8982-4491-8188-8da693e2f0d6",
   "metadata": {},
   "source": [
    "## OneVs Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf1a093-31e0-45b4-9e44-c2d0f7f42769",
   "metadata": {},
   "source": [
    "Änderung:\n",
    "- kmnist_tr und kmnist_ts wurden die Form der x auf [1, 28, 28 ,1] geändert\n",
    "- Reihenfolge der Datasets beachten! Erst nach Konkenation in und out_distro bilden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433034c3-61b2-46af-9d0f-443c6090cc89",
   "metadata": {
    "tags": []
   },
   "source": [
    "### One Vs Rest wirklich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57969b3-54aa-4e98-b8f9-bd739dc58b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAINING_ONE_IN = 3\n",
    "N_TRAINING_ONE_REST = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25248052-3714-47c8-be0d-a72eb9504e61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "60 \\//// 6\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.2362\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.5069\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3495\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6381\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3564\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3311\n",
      "====================\n",
      "61 \\//// 6\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.8797\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.2558\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8503\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0952\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.5665\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4217\n",
      "====================\n",
      "5 \\//// 6\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 1.2346\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.0016\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2346\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.3650\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1541\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9786\n",
      "====================\n",
      "14 \\//// 6\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.7727\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0281\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6851\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0498\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0778\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.4289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 14:42:49.480394: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 779 of 1000\n",
      "2022-07-26 14:42:51.543428: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "17 \\//// 6\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.6929\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1041\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.3577\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3947\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9353\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4429\n"
     ]
    }
   ],
   "source": [
    "cloned_models = dict()\n",
    "for ofd in out_of_distro_classes_list:\n",
    "    cloned_models[ofd] = tf.keras.models.clone_model(cnn_model)\n",
    "    cloned_models[ofd].compile( tf.keras.optimizers.SGD(), tf.keras.losses.BinaryCrossentropy(from_logits=True))\n",
    "\n",
    "    training_elements = list()\n",
    "    \n",
    "    ## todo: warum 8, dann vier. _Vermutlich out_distribution\n",
    "    for i, (x, _) in enumerate(out_of_distro_tr[ofd]):\n",
    "        if i >= N_TRAINING_ONE_IN:\n",
    "            break\n",
    "        training_elements.append((x, tf.ones([1,1])))    for i, (x, _) in enumerate(in_of_distro_tr[ofd]):\n",
    "        if i >= N_TRAINING_ONE_REST:\n",
    "            break\n",
    "        training_elements.append((x, tf.zeros([1, 1])))\n",
    "\n",
    "    shuffle(training_elements)\n",
    "    print(\"ofd\", ofd)\n",
    "    for x, y in training_elements:\n",
    "        cloned_models[ofd].fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccdd8628-ce16-4281-a97f-4fa156cca97b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[0.]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[0.]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[0.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for _, y in training_elements:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01bbbd4f-3c13-425c-80ae-0a229847d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, _ in kmnist_ts:\n",
    "    cloned_models[ofd](x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "247a4c11-505c-4fdc-8ddc-53049ea495a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pred_classes = list()\n",
    "list_true_classes = list()\n",
    "for i, (x, y) in enumerate(kmnist_ts):\n",
    "    if i > 100:\n",
    "        break\n",
    "    predictions = list()\n",
    "    for ofd in out_of_distro_classes_list:\n",
    "        pred_ofd = cloned_models[ofd](x)\n",
    "        predictions.append((ofd, pred_ofd))\n",
    "\n",
    "    max_pred_class, _ = max(predictions, key=lambda x: x[1])\n",
    "    list_true_classes.append(int(y))\n",
    "    list_pred_classes.append(max_pred_class)\n",
    "\n",
    "accuracy = accuracy_score(list_true_classes, list_pred_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdd3e7cc-51ee-4150-b256-9e60a4eb371b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.009900990099009901,\n",
       " [55,\n",
       "  8,\n",
       "  68,\n",
       "  3,\n",
       "  65,\n",
       "  21,\n",
       "  67,\n",
       "  12,\n",
       "  55,\n",
       "  5,\n",
       "  4,\n",
       "  6,\n",
       "  28,\n",
       "  58,\n",
       "  0,\n",
       "  8,\n",
       "  8,\n",
       "  55,\n",
       "  61,\n",
       "  1,\n",
       "  62,\n",
       "  4,\n",
       "  30,\n",
       "  13,\n",
       "  14,\n",
       "  53,\n",
       "  28,\n",
       "  43,\n",
       "  0,\n",
       "  8,\n",
       "  7,\n",
       "  2,\n",
       "  18,\n",
       "  21,\n",
       "  27,\n",
       "  9,\n",
       "  3,\n",
       "  33,\n",
       "  6,\n",
       "  4,\n",
       "  40,\n",
       "  43,\n",
       "  18,\n",
       "  8,\n",
       "  13,\n",
       "  62,\n",
       "  11,\n",
       "  28,\n",
       "  0,\n",
       "  63,\n",
       "  63,\n",
       "  18,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  36,\n",
       "  4,\n",
       "  60,\n",
       "  11,\n",
       "  65,\n",
       "  6,\n",
       "  5,\n",
       "  38,\n",
       "  2,\n",
       "  36,\n",
       "  2,\n",
       "  12,\n",
       "  40,\n",
       "  63,\n",
       "  9,\n",
       "  24,\n",
       "  10,\n",
       "  7,\n",
       "  52,\n",
       "  4,\n",
       "  67,\n",
       "  5,\n",
       "  18,\n",
       "  41,\n",
       "  23,\n",
       "  2,\n",
       "  5,\n",
       "  4,\n",
       "  69,\n",
       "  3,\n",
       "  67,\n",
       "  43,\n",
       "  0,\n",
       "  40,\n",
       "  32,\n",
       "  16,\n",
       "  43,\n",
       "  30,\n",
       "  25,\n",
       "  62,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  24,\n",
       "  24,\n",
       "  22],\n",
       " [61,\n",
       "  17,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  17,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  17,\n",
       "  61,\n",
       "  61,\n",
       "  17,\n",
       "  61,\n",
       "  61,\n",
       "  17,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  17,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  17,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  17,\n",
       "  17,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  17,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  61,\n",
       "  17,\n",
       "  61,\n",
       "  61,\n",
       "  61])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy, list_true_classes, list_pred_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7a68ee-a4d4-49c0-bce5-8f98c7147f13",
   "metadata": {},
   "source": [
    "## OnevsOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8055234-a707-4c15-8cab-dacd61292204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 337ms/step - loss: 0.2620\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.5908\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0611\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.9406\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6729\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4378\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3783\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8880\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.3416\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.4275\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.5072\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3533\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6882\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7271\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9060\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4344\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.1245\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.3209\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6298\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1501\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0227\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6876\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9267\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 15:20:03.695317: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 987 of 1000\n",
      "2022-07-26 15:20:03.841534: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 343ms/step - loss: 0.3896\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0389\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1062\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.4081\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5044\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5431\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6467\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 15:20:18.333604: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 970 of 1000\n",
      "2022-07-26 15:20:18.552304: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 332ms/step - loss: 0.8220\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0284\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.2169\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4557\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2438\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1649\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9290\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 15:20:33.071359: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 994 of 1000\n",
      "2022-07-26 15:20:33.147535: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 330ms/step - loss: 0.5090\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.8264e-05\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.5004\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0047\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0067\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.4095\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6667\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 15:20:47.497438: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 741 of 1000\n",
      "2022-07-26 15:20:49.839472: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 343ms/step - loss: 0.5843\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.8107\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1375\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3298\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7737\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6718\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8802\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 15:21:04.089538: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 684 of 1000\n",
      "2022-07-26 15:21:07.206101: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 349ms/step - loss: 0.4495\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0241\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.5107\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0123\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.5227\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0592\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.4567\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 15:21:21.610227: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 686 of 1000\n",
      "2022-07-26 15:21:24.830812: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 332ms/step - loss: 0.5264\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1031\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4275\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2058\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1365\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3926\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8340\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 15:21:40.168092: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 585 of 1000\n",
      "2022-07-26 15:21:44.504907: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 334ms/step - loss: 0.2108\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0136\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0196\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.3181\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1181\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0806\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9350\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8739\n"
     ]
    }
   ],
   "source": [
    "used_pairs = list()\n",
    "cloned_models = dict()\n",
    "\n",
    "for ofd_outer in out_of_distro_classes_list:\n",
    "    for ofd_inner in out_of_distro_classes_list:\n",
    "        print(ofd_outer, ofd_innerb)\n",
    "        if (ofd_outer, ofd_inner) in used_pairs or \\\n",
    "            (ofd_inner, ofd_outer) in used_pairs or \\\n",
    "            ofd_inner == ofd_outer:\n",
    "            break\n",
    "\n",
    "        used_pairs.append((ofd_outer, ofd_inner))\n",
    "        training_elements = list()\n",
    "\n",
    "        for i, (x, _) in enumerate(out_of_distro_tr[ofd_outer]):\n",
    "            if i >= 3:\n",
    "                break\n",
    "            training_elements.append((x, tf.ones([1,1])))\n",
    "\n",
    "        for i, (x, _) in enumerate(in_of_distro_tr[ofd_inner]):\n",
    "            if i >= 3:\n",
    "                break\n",
    "            training_elements.append((x, tf.zeros([1, 1])))\n",
    "\n",
    "        cloned_models[(ofd_outer, ofd_inner)] = tf.keras.models.clone_model(cnn_model)\n",
    "        cloned_models[(ofd_outer, ofd_inner)].compile( \n",
    "            tf.keras.optimizers.SGD(), \n",
    "            tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "            )\n",
    "\n",
    "        shuffle(training_elements)\n",
    "\n",
    "        for x, y in training_elements:\n",
    "            cloned_models[(ofd_outer, ofd_inner)].fit(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f8df612-9894-4284-98bd-b0a715df87b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(61, 60),\n",
       " (5, 60),\n",
       " (5, 61),\n",
       " (14, 60),\n",
       " (14, 61),\n",
       " (14, 5),\n",
       " (17, 60),\n",
       " (17, 61),\n",
       " (17, 5),\n",
       " (17, 14)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c916241-e38f-464d-b9df-f41c6f310ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pred_classes = list()\n",
    "list_true_classes = list()\n",
    "\n",
    "for i, (x, y) in enumerate(kmnist_ts):\n",
    "    if i > 100:\n",
    "        break\n",
    "\n",
    "    predictions_votes = list()\n",
    "\n",
    "    for ofd_outter, ofd_inner in cloned_models:\n",
    "        pred = cloned_models[(ofd_outter, ofd_inner)](x)\n",
    "        if pred >= 0.5:\n",
    "            predictions_votes.append(ofd_outter)\n",
    "        else:\n",
    "            predictions_votes.append(ofd_inner)\n",
    "\n",
    "    ##calculates, which vote / elemenst is most frequent\n",
    "    prediction_counter = Counter(predictions_votes)\n",
    "    most_common_vote = prediction_counter.most_common(1)[0][0]\n",
    "\n",
    "    list_pred_classes.append(most_common_vote)\n",
    "    list_true_classes.append(int(y))\n",
    "\n",
    "accuracy = accuracy_score(list_true_classes, list_pred_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e7fc059-cde0-4908-9c07-bfefcd227b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.009900990099009901,\n",
       " [30,\n",
       "  5,\n",
       "  4,\n",
       "  20,\n",
       "  14,\n",
       "  7,\n",
       "  0,\n",
       "  3,\n",
       "  37,\n",
       "  66,\n",
       "  39,\n",
       "  5,\n",
       "  4,\n",
       "  2,\n",
       "  53,\n",
       "  32,\n",
       "  15,\n",
       "  1,\n",
       "  55,\n",
       "  39,\n",
       "  61,\n",
       "  55,\n",
       "  55,\n",
       "  2,\n",
       "  9,\n",
       "  30,\n",
       "  7,\n",
       "  43,\n",
       "  7,\n",
       "  47,\n",
       "  3,\n",
       "  0,\n",
       "  7,\n",
       "  10,\n",
       "  7,\n",
       "  3,\n",
       "  49,\n",
       "  8,\n",
       "  6,\n",
       "  6,\n",
       "  2,\n",
       "  7,\n",
       "  61,\n",
       "  49,\n",
       "  9,\n",
       "  49,\n",
       "  64,\n",
       "  15,\n",
       "  63,\n",
       "  40,\n",
       "  2,\n",
       "  13,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  18,\n",
       "  11,\n",
       "  2,\n",
       "  34,\n",
       "  64,\n",
       "  53,\n",
       "  12,\n",
       "  8,\n",
       "  40,\n",
       "  63,\n",
       "  29,\n",
       "  0,\n",
       "  5,\n",
       "  50,\n",
       "  65,\n",
       "  9,\n",
       "  62,\n",
       "  4,\n",
       "  6,\n",
       "  3,\n",
       "  48,\n",
       "  65,\n",
       "  0,\n",
       "  29,\n",
       "  40,\n",
       "  7,\n",
       "  18,\n",
       "  12,\n",
       "  40,\n",
       "  33,\n",
       "  1,\n",
       "  64,\n",
       "  1,\n",
       "  3,\n",
       "  66,\n",
       "  0,\n",
       "  24,\n",
       "  7,\n",
       "  40,\n",
       "  25,\n",
       "  4,\n",
       "  42,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  42],\n",
       " [61,\n",
       "  60,\n",
       "  5,\n",
       "  60,\n",
       "  5,\n",
       "  61,\n",
       "  60,\n",
       "  60,\n",
       "  5,\n",
       "  61,\n",
       "  61,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  61,\n",
       "  14,\n",
       "  5,\n",
       "  61,\n",
       "  60,\n",
       "  61,\n",
       "  5,\n",
       "  60,\n",
       "  60,\n",
       "  61,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  61,\n",
       "  5,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  14,\n",
       "  60,\n",
       "  60,\n",
       "  61,\n",
       "  5,\n",
       "  60,\n",
       "  60,\n",
       "  61,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  61,\n",
       "  61,\n",
       "  5,\n",
       "  5,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  61,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  14,\n",
       "  61,\n",
       "  60,\n",
       "  60,\n",
       "  5,\n",
       "  61,\n",
       "  61,\n",
       "  60,\n",
       "  60,\n",
       "  61,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  61,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  61,\n",
       "  60,\n",
       "  5,\n",
       "  60,\n",
       "  60,\n",
       "  61,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  60,\n",
       "  61])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy, list_true_classes, list_pred_classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
